{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ventSegUnetMain.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "lZ6O_5phMmf3"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mullen44/Segmentation-Ventricle/blob/main/ventSegUnetMain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZ6O_5phMmf3"
      },
      "source": [
        "# GPU Allocation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaSrKCU4Q-WI"
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "# retrieve GPU type\n",
        "GPUs = GPU.getGPUs()\n",
        "gpu = GPUs[0]\n",
        "# check allocation of GPU resources\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0pHkw4_MY26"
      },
      "source": [
        "# Mount Drive / Load Modules\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2uWdioQNbvl"
      },
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IhmuyifHW8g"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "from scipy.spatial.distance import dice\n",
        "import random\n",
        "from PIL import Image\n",
        "from matplotlib.pyplot import imsave, imread\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import csv\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, CSVLogger, LearningRateScheduler\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.python.keras.utils.data_utils import Sequence\n",
        "%load_ext tensorboard\n",
        "\n",
        "print(tensorflow.__version__)\n",
        "\n",
        "%cd /content/gdrive/Shared drives/Andrew Mullen/Ventricle Segmentation/\n",
        "from unet import *\n",
        "from unet3 import *\n",
        "from utilities import *\n",
        "from data_generator_keras import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7h3dOxqSZ5vA"
      },
      "source": [
        "# Authenticate and create the PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzJS6jEBFCSe"
      },
      "source": [
        "%cd /content/gdrive/My Drive/NeuralNetworkTools/\n",
        "!pip install SimpleITK\n",
        "from data_generator import *\n",
        "from loss_functions import *\n",
        "from models import *\n",
        "from utils import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdppEJBpMg3P"
      },
      "source": [
        "# Divide Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfaNaueNdhpQ"
      },
      "source": [
        "%cd /content/gdrive/Shared drives/Andrew Mullen/Ventricle Segmentation/\n",
        "# Specify the path of the ground truths and volumes\n",
        "VOL_path = 'Data/Standardized/v2/'\n",
        "GT_path = 'Data/Ground Truths/'\n",
        "BRAIN_path = 'Data/Masks/Brain/U-Net/'\n",
        "\n",
        "VOL, GT = createFileList(vol_path=VOL_path, gt_path=GT_path, brain_path=BRAIN_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JHDPAcVzAMD"
      },
      "source": [
        "# Initialize\n",
        "TrainPercent = 0.85\n",
        "ValPercent = 0.2\n",
        "\n",
        "# Divide into train and test datasets\n",
        "DATA, Train_Index, Val_Index = divideData(train_percentage=TrainPercent, val_percentage=ValPercent, vol=VOL, gt=GT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzH-f0XJApso"
      },
      "source": [
        "# Divide train_vol/GT into layers/images\n",
        "Train_Path = 'Data/train/'\n",
        "Val_Path = 'Data/val/'\n",
        "Test_Path = 'Data/test/'\n",
        "\n",
        "Train_Len = 0\n",
        "Val_Len = 0\n",
        "\n",
        "\n",
        "Vol_Dir = os.listdir(VOL_path)\n",
        "\n",
        "# Check if directory is empty before refilling it\n",
        "if len(os.listdir(Train_Path + 'images')) == 0 :\n",
        "  print('Saving...')\n",
        "  # Save images to Directory\n",
        "  for i in range(len(VOL)) :\n",
        "    if i not in Train_Index and i not in Val_Index :\n",
        "      # Save to test folder\n",
        "      Path_Image = Test_Path + 'inputs/' + Vol_Dir[i][:-4]\n",
        "      Path_Label = Test_Path + 'targets/' + Vol_Dir[i][:-4]\n",
        "\n",
        "      image = VOL[i].astype(np.float32)\n",
        "      label = GT[i].astype(np.uint8)\n",
        "\n",
        "      image = (image-np.amin(image))/(np.amax(image)-np.amin(image))\n",
        "\n",
        "      np.save(Path_Image, image)\n",
        "      np.save(Path_Label, label)\n",
        "    else :\n",
        "      for j in range(VOL[i].shape[2]) :\n",
        "        if i in Train_Index :\n",
        "          # Save to train folder\n",
        "          Path_Image = Train_Path + 'images/' + Vol_Dir[i][:-4] + '_slice_' + str(j) +'.png'\n",
        "          Path_Label = Train_Path + 'labels/' + Vol_Dir[i][:-4] + '_slice_' + str(j) +'.png'\n",
        "\n",
        "          #image = Image.fromarray(VOL[i][:,:,j].astype(np.uint8))\n",
        "          #image.convert('gray')\n",
        "          #label = Image.fromarray(VOL[i][:,:,j].astype(np.uint8))\n",
        "\n",
        "          #image.save(Path_Image)\n",
        "          #label.save(Path_Label)\n",
        "\n",
        "          image = VOL[i][:,:,j].astype(np.float32)\n",
        "          label = GT[i][:,:,j].astype(np.uint8)\n",
        "\n",
        "          image = (image-np.amin(image))/(np.amax(image)-np.amin(image))\n",
        "\n",
        "          print(np.unique(label))\n",
        "\n",
        "          imsave(Path_Image, image, cmap='gray', origin='upper')\n",
        "          imsave(Path_Label, label, cmap='gray', origin='upper')\n",
        "\n",
        "        elif i in Val_Index :\n",
        "          # Save to val folder\n",
        "        \n",
        "          Path_Image = Val_Path + 'images/' + Vol_Dir[i][:-4] + '_slice_' + str(j) +'.png'\n",
        "          Path_Label = Val_Path + 'labels/' + Vol_Dir[i][:-4] + '_slice_' + str(j) +'.png'\n",
        "\n",
        "          #image = Image.fromarray(VOL[i][:,:,j].astype(np.uint8))\n",
        "          #label = Image.fromarray(VOL[i][:,:,j].astype(np.uint8))\n",
        "\n",
        "          #image.save(Path_Image)\n",
        "          #label.save(Path_Label)\n",
        "\n",
        "          image = VOL[i][:,:,j].astype(np.float32)\n",
        "          label = GT[i][:,:,j].astype(np.uint8)\n",
        "\n",
        "          image = (image-np.amin(image))/(np.amax(image)-np.amin(image))\n",
        "\n",
        "          print(np.unique(label))\n",
        "\n",
        "          imsave(Path_Image, image, cmap='gray', origin='upper') #vmin=0.0, vmax=255.0,\n",
        "          imsave(Path_Label, label, cmap='gray', origin='upper') #vmin=0.0, vmax=255.0,\n",
        "\n",
        "\n",
        "else : \n",
        "  print('Already Filled')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yy2Fe_Rp_rNF"
      },
      "source": [
        "#Model Training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVMUO9PoRmMe"
      },
      "source": [
        "#model = Unet()\n",
        "choice = 'uresnet'\n",
        "model, params = select_model(choice = choice)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueS70gFdUxnj"
      },
      "source": [
        "def scheduler(epoch) :\n",
        "  if epoch < 40 :\n",
        "    return 5e-5\n",
        "  if epoch >= 40 :\n",
        "    return 1e-5\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFZddPYQjJpG"
      },
      "source": [
        "# Initialize\n",
        "FILEPATH = '/content/gdrive/Shared drives/Andrew Mullen/Ventricle Segmentation/Models/'\n",
        "EPOCHS = 100\n",
        "STEPS = 70 #len(DATA['train_vol']) // BS\n",
        "valSTEPS = 15 #len(DATA['val_vol']) // BS\n",
        "BS = 32 # 1 = Optimal\n",
        "lr = 1e-4\n",
        "Model_Name = choice + '_batch_' + str(BS) + '_lr_' + str(lr) + '/'\n",
        "FILEPATH = FILEPATH + Model_Name\n",
        "\n",
        "# Specify dictionary of arguments for ImageDataGenerator Class\n",
        "train_args = dict(rotation_range=0.2,\n",
        "                  width_shift_range=0.05,\n",
        "                  height_shift_range=0.05,\n",
        "                  shear_range=0.05,\n",
        "                  zoom_range=0.05,\n",
        "                  fill_mode='nearest',\n",
        "\t\t\t\t\t\t\t\t\trescale = 1.0/255) # Try changing this to 1./255\n",
        "\n",
        "val_args = dict(rescale = 1.0/255)\n",
        "\n",
        "# Create the generators\n",
        "train_gen = train_generator(Train_Path, train_args, batch_size=BS)\n",
        "val_gen = val_generator(Val_Path, val_args, batch_size=BS)\n",
        "\n",
        "\n",
        "if os.path.isdir(FILEPATH) == 0 :\n",
        "  os.mkdir(FILEPATH)\n",
        "  print('Creating Directory')\n",
        "\n",
        "# Set Callbacks\n",
        "model_checkpoint = ModelCheckpoint(FILEPATH + 'model.hdf5', monitor='val_loss', save_best_only=True)\n",
        "early_stop = EarlyStopping(monitor = 'val_loss', patience = 8)\n",
        "t_board = TensorBoard(FILEPATH + './logs')\n",
        "csv_logger = CSVLogger(FILEPATH + 'model_test.csv')\n",
        "schedule = LearningRateScheduler(scheduler, verbose=1)\n",
        "\n",
        "CALLBACKS = [model_checkpoint, early_stop, t_board, csv_logger]\n",
        "\n",
        "# Compile Model\n",
        "model.compile(optimizer=Adam(lr), loss=dice_loss, metrics=[DSC]) \n",
        "\n",
        "# Fit Model\n",
        "model_history = model.fit_generator(train_gen, \n",
        "                    validation_data=val_gen, \n",
        "                    validation_steps=valSTEPS, \n",
        "                    steps_per_epoch=STEPS, \n",
        "                    epochs=EPOCHS, \n",
        "                    callbacks=[model_checkpoint, early_stop, t_board, csv_logger])#, schedule])\n",
        "                                   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43vlksqeSRzy"
      },
      "source": [
        "# Plot Loss Curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCIDA1M8SRUy"
      },
      "source": [
        "FILEPATH = '/content/gdrive/Shared drives/Andrew Mullen/Ventricle Segmentation/Models/uresnet_batch_4_lr_0.0001/'\n",
        "CSVfile = FILEPATH + 'model_test.csv'\n",
        "#CSVfile = '/content/gdrive/Shared drives/Andrew Mullen/Ventricle Segmentation/Models/uresnet_batch_16_epochs_100_steps_139_lr_0.0001model_test.csv'\n",
        "model_curves = pd.read_csv(CSVfile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsAWL5OdUePi"
      },
      "source": [
        "print(min(model_curves['loss']))\n",
        "print(max(model_curves['DSC']))\n",
        "print(min(model_curves['val_loss']))\n",
        "print(max(model_curves['val_DSC']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWtmex1xwEFP"
      },
      "source": [
        "# Plot loss vs epochs\n",
        "plt.plot(model_curves['loss'], label='Training Loss')\n",
        "plt.plot(model_curves['val_loss'], label='Validation Loss')\n",
        "plt.ylabel('Dice Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.title('Loss Curve')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot DSC vs epochs\n",
        "plt.plot(model_curves['DSC'], label='Training DSC')\n",
        "plt.plot(model_curves['val_DSC'], label='Validation DSC')\n",
        "plt.ylabel('DSC')\n",
        "plt.xlabel('Epochs')\n",
        "plt.title('DSC Curve')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3m1uRAO7QXF"
      },
      "source": [
        "FILEPATH = '/content/gdrive/Shared drives/Andrew Mullen/Ventricle Segmentation/Models/Unet3_batch_16_epochs_100_steps_139_sched/'\n",
        "CSVfile = FILEPATH + 'model_test.csv'\n",
        "BS_16 = pd.read_csv(CSVfile)\n",
        "\n",
        "FILEPATH = '/content/gdrive/Shared drives/Andrew Mullen/Ventricle Segmentation/Models/Unet3_batch_8_epochs_100_steps_280_sched/'\n",
        "CSVfile = FILEPATH + 'model_test.csv'\n",
        "BS_8 = pd.read_csv(CSVfile)\n",
        "\n",
        "FILEPATH = '/content/gdrive/Shared drives/Andrew Mullen/Ventricle Segmentation/Models/Unet3_batch_4_epochs_100_steps_560_sched/'\n",
        "CSVfile = FILEPATH + 'model_test.csv'\n",
        "BS_4 = pd.read_csv(CSVfile)\n",
        "\n",
        "FILEPATH = '/content/gdrive/Shared drives/Andrew Mullen/Ventricle Segmentation/Models/Unet3_batch_2_epochs_100_steps_1120_sched/'\n",
        "CSVfile = FILEPATH + 'model_test.csv'\n",
        "BS_2 = pd.read_csv(CSVfile)\n",
        "\n",
        "f, axarr = plt.subplots(2,2,figsize=(15,10))\n",
        "axarr[0,0].plot(BS_16['val_DSC'], '-r', label='BS_16 - Val DSC')\n",
        "axarr[0,0].plot(BS_8['val_DSC'], '-b', label='BS_8 - Val DSC')\n",
        "axarr[0,0].plot(BS_4['val_DSC'], '-g', label='BS_4 - Val DSC')\n",
        "axarr[0,0].plot(BS_2['val_DSC'], '-k', label='BS_2 - Val DSC')\n",
        "axarr[0,0].legend()\n",
        "axarr[0,0].set_title('Validation DSC')\n",
        "axarr[0,0].set(ylabel='DSC',xlabel='Epochs')\n",
        "\n",
        "#plt.figure(figsize=(12,7))\n",
        "axarr[0,1].plot(BS_16['DSC'], '-r', label='BS_16')\n",
        "axarr[0,1].plot(BS_8['DSC'], '-b', label='BS_8')\n",
        "axarr[0,1].plot(BS_4['DSC'], '-g', label='BS_4')\n",
        "axarr[0,1].plot(BS_2['DSC'], '-k', label='BS_2')\n",
        "axarr[0,1].legend()\n",
        "axarr[0,1].set_title('Train DSC')\n",
        "axarr[0,1].set(ylabel='DSC',xlabel='Epochs')\n",
        "\n",
        "#plt.figure(figsize=(12,7))\n",
        "axarr[1,0].plot(BS_16['val_loss'], '-r', label='BS_16')\n",
        "axarr[1,0].plot(BS_8['val_loss'], '-b', label='BS_8')\n",
        "axarr[1,0].plot(BS_4['val_loss'], '-g', label='BS_4')\n",
        "axarr[1,0].plot(BS_2['val_loss'], '-k', label='BS_2')\n",
        "axarr[1,0].legend()\n",
        "axarr[1,0].set_title('Validation Loss')\n",
        "axarr[1,0].set(ylabel='Loss',xlabel='Epochs')\n",
        "\n",
        "#plt.figure(figsize=(12,7))\n",
        "axarr[1,1].plot(BS_16['loss'], '-r', label='BS_16')\n",
        "axarr[1,1].plot(BS_8['loss'], '-b', label='BS_8')\n",
        "axarr[1,1].plot(BS_4['loss'], '-g', label='BS_4')\n",
        "axarr[1,1].plot(BS_2['loss'], '-k', label='BS_2')\n",
        "axarr[1,1].legend()\n",
        "axarr[1,1].set_title('Training Loss')\n",
        "axarr[1,1].set(ylabel='DSC',xlabel='Epochs')\n",
        "\n",
        "for ax in f.get_axes():\n",
        "    ax.label_outer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jHZZeFYZn2I"
      },
      "source": [
        "# Test Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZqiEvtNjVjR"
      },
      "source": [
        "# File Paths\n",
        "vol_path = '/content/gdrive/Shared drives/Andrew Mullen/Ventricle Segmentation/Data/test/inputs/'\n",
        "gt_path = '/content/gdrive/Shared drives/Andrew Mullen/Ventricle Segmentation/Data/test/targets/'\n",
        "model_path = '/content/gdrive/Shared drives/Andrew Mullen/Ventricle Segmentation/Models/uresnet_batch_8_lr_0.0001/model.hdf5'\n",
        "#model_path = '/content/gdrive/Shared drives/Andrew Mullen/Ventricle Segmentation/Models/uresnet_batch_16_epochs_100_steps_139_lr_0.0001model.hdf5'\n",
        "\n",
        "# Load model\n",
        "model, params = select_model(choice = 'uresnet')\n",
        "#model = Unet3()\n",
        "model.load_weights(model_path)\n",
        "\n",
        "# Make Predictions\n",
        "i = 0\n",
        "DSC = []\n",
        "EF = []\n",
        "predict = []\n",
        "ground = []\n",
        "name = []\n",
        "for file in os.listdir(vol_path) :\n",
        "  print(file)\n",
        "  name.append(file)\n",
        "\n",
        "  # Load Data\n",
        "  vol = np.load(vol_path + file)\n",
        "  test_gt = np.load(gt_path + file)\n",
        "  print('Vol shape:', vol.shape)\n",
        "\n",
        "  # Normalize/Binarize GT\n",
        "  test_gt = test_gt/np.max(test_gt)\n",
        "  test_gt[test_gt>0.5] = 1\n",
        "  test_gt[test_gt<=0.5] = 0\n",
        "  test_gt = test_gt.astype(np.uint8)\n",
        "  ground.append(test_gt)\n",
        "  #print('Volume max and min:', np.max(test_vol), np.min(test_vol), test_vol.shape, 'GT max and min:', np.max(test_gt), np.min(test_gt), np.unique(test_gt), test_gt.shape)\n",
        "\n",
        "  # Save originial dimensions\n",
        "  vol_size = (vol.shape[0:2])\n",
        "\n",
        "  # Make Predictions\n",
        "  test_pred = getPred(vol, model)#, img_size=(vol_size[0], vol_size[1]))\n",
        "\n",
        "  pred = np.zeros(test_gt.shape)\n",
        "\n",
        "  for j in range(test_pred.shape[2]) :\n",
        "    pred[:,:,j] = cv2.resize(test_pred[:,:,j], (test_gt.shape[1], test_gt.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
        "    pred[:,:,j] = Binarize(pred[:,:,j], 0.5)\n",
        "\n",
        "  #test_pred = Binarize(test_pred, 0.5)\n",
        "  predict.append(pred)\n",
        "\n",
        "  print(test_gt.shape, pred.shape)\n",
        "\n",
        "  # Evaluate predictions\n",
        "  y_true = test_gt.flatten()\n",
        "  y_pred = pred.flatten()\n",
        "  print('y_true shape:', y_true.shape, 'y_pred shape:', y_pred.shape)\n",
        "  DSC.append(1 - dice(y_true, y_pred))\n",
        "  i+=1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKU_I8xHTkfy"
      },
      "source": [
        "x_dim = [0.8594, 0.8594, 0.8594, 0.8594, 0.8594, 0.8594, 1, 0.4286, 0.8594, 0.4286, 1]\n",
        "y_dim = x_dim\n",
        "z_dim = [5, 5, 5, 5, 5, 3, 3, 5, 3, 3, 3]\n",
        "volGT = []\n",
        "volPred = []\n",
        "VOL = {}\n",
        "\n",
        "\n",
        "for i in range(len(ground)) :\n",
        "  vol = (x_dim[i]*y_dim[i]*z_dim[i])*len(ground[i][ground[i]==1])\n",
        "  volGT.append(vol/1000)\n",
        "  vol = (x_dim[i]*y_dim[i]*z_dim[i])*len(predict[i][predict[i]==1])\n",
        "  volPred.append(vol/1000)\n",
        "  VOL[name[i]] = vol"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APpOp7q8uYMG"
      },
      "source": [
        "EF = {}\n",
        "D = {}\n",
        "for i in range(len(predict)) :\n",
        "  TP, FN, TN, FP = performance_measure(ground[i], predict[i])\n",
        "  EF[name[i]] = (FP / (TP + FN))\n",
        "  D[name[i]] = DSC[i]\n",
        "\n",
        "\n",
        "print(EF)\n",
        "print(D)\n",
        "print(VOL)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fN2VB3mn8dYK"
      },
      "source": [
        "# Save Dictionary Files\n",
        "\n",
        "w = csv.writer(open(\"DSC.csv\", \"w\"))\n",
        "for key, val in D.items():\n",
        "  w.writerow([key, val])\n",
        "\n",
        "a = csv.writer(open(\"EF.csv\", \"w\"))\n",
        "for key, val in EF.items():\n",
        "  a.writerow([key, val])\n",
        "\n",
        "b = csv.writer(open(\"Volume.csv\", \"w\"))\n",
        "for key, val in VOL.items():\n",
        "  b.writerow([key, val])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XYNxpnmayiy"
      },
      "source": [
        "for i in range(len(DSC)) :\n",
        "  print(i, name[i], DSC[i], EF[i], volPred[i], volGT[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqdsneIX1EJz"
      },
      "source": [
        "print(sum(DSC)/len(DSC))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCM8TMKEMFHa"
      },
      "source": [
        "x = EF.values()\n",
        "sum(x)/11"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGwuStQGFBFG"
      },
      "source": [
        "# Statistical Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7SnhAMNopvH"
      },
      "source": [
        "vol=0\n",
        "layer=28\n",
        "img=DATA['test_vol']\n",
        "gt=DATA['test_gt']\n",
        "pred=predict\n",
        "\n",
        "print(name[vol])\n",
        "\n",
        "plotImgGtPred(vol=vol, layer=layer, img=img, gt=gt, pred=pred)\n",
        "\n",
        "img_1 = DATA['test_gt'][vol][:,:,layer]\n",
        "img_2 = predict[vol][:,:,layer]\n",
        "plt.figure()\n",
        "plt.imshow(img_1)\n",
        "plt.imshow(img_2, alpha=0.5)\n",
        "plt.title('Overlay')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_yLwRQJk8A_"
      },
      "source": [
        "DSC_unsup = np.array(loadmat('/content/gdrive/Shared drives/Andrew Mullen/Ventricle Segmentation/Data/DSC_uns_test.mat')['DSC'])\n",
        "a = pd.read_csv('/content/gdrive/Shared drives/Andrew Mullen/Ventricle Segmentation/Data/DSC_Unet.csv')\n",
        "b = pd.read_csv('/content/gdrive/Shared drives/Andrew Mullen/Ventricle Segmentation/Data/DSC_Uresnet.csv')\n",
        "print(b)\n",
        "\n",
        "DSC_Unet = [0.9381, 0.9580, 0.9421, 0.9368, 0.9247, 0.9263, 0.8734, 0.8886, 0.8947, 0.8347, 0.8654]\n",
        "DSC_Uresnet = [0.9435, 0.9475, 0.9151, 0.9181, 0.9026, 0.8843, 0.8287, 0.8667, 0.8752, 0.8215, 0.8241]\n",
        "\n",
        "print(len(DSC_Uresnet))\n",
        "\n",
        "\n",
        "data = [DSC_unsup, DSC_Unet, DSC_Uresnet]\n",
        "plt.figure()\n",
        "plt.boxplot(data)\n",
        "plt.xticks([1, 2, 3],['Unsupervised','Unet', 'Uresnet'])\n",
        "plt.ylim(0, 1)\n",
        "plt.ylabel('Dice Score')\n",
        "plt.title('DSC')\n",
        "plt.imshow\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-FdMiAqKn0Z"
      },
      "source": [
        "EF_unsup = np.array(loadmat('/content/gdrive/Shared drives/Andrew Mullen/Ventricle Segmentation/Data/EF_unsup.mat')['EF'])\n",
        "EF_unsup = np.squeeze(EF_unsup)\n",
        "a = pd.read_csv('/content/gdrive/Shared drives/Andrew Mullen/Ventricle Segmentation/Data/EF_Unet.csv')\n",
        "b = pd.read_csv('/content/gdrive/Shared drives/Andrew Mullen/Ventricle Segmentation/Data/EF_Uresnet.csv')\n",
        "print(EF_unsup)\n",
        "\n",
        "EF_Unet = [0.0053,  0.0213, 0.0423, 0.0511, 0.0510, 0.0777, 0.1784, 0.0475, 0.0317, 0.0731, 0.0988]\n",
        "EF_Uresnet = [0.0121, 0.0311, 0.0556, 0.0768, 0.0678, 0.1834, 0.2348, 0.0625, 0.0867, 0.1597, 0.1715]\n",
        "\n",
        "print(len(EF_Uresnet))\n",
        "\n",
        "\n",
        "data = [EF_unsup, EF_Unet, EF_Uresnet]\n",
        "plt.figure()\n",
        "plt.boxplot(data)\n",
        "plt.xticks([1, 2, 3],['Unsupervised','Unet', 'Uresnet'])\n",
        "plt.ylim(0, 1)\n",
        "plt.ylabel('EF')\n",
        "plt.title('Extra Fraction')\n",
        "plt.imshow\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBKmEeliS4ll"
      },
      "source": [
        "print(sum(DSC_Uresnet)/11, sum(EF_Uresnet)/11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CX3CHszywGS"
      },
      "source": [
        "DSC = np.array(DSC)\n",
        "print(len(DSC))\n",
        "DSC_philip = DSC[[1,3,7,9]]\n",
        "DSC_siem = DSC[[2,4,6,10]]\n",
        "DSC_ge = DSC[[0,5,8]]\n",
        "print(DSC_philip, len(DSC_philip))\n",
        "data = [DSC_ge, DSC_philip, DSC_siem]\n",
        "plt.boxplot(data)\n",
        "plt.xticks([1,2,3],['GE', 'Philips', 'Siemens'])\n",
        "plt.title('DSC by MRI Manufacturer')\n",
        "plt.ylabel('DSC')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17TpYU8c55dY"
      },
      "source": [
        "# Volume predicted + Volume ground truth vs ground truth\n",
        "\n",
        "DSC = np.array(DSC)\n",
        "volGT = np.array(volGT)\n",
        "volPred = np.array(volPred)\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(volGT, DSC)\n",
        "m, b = np.polyfit(volGT, DSC, 1)\n",
        "plt.plot(volGT, m*volGT+b, color='red')\n",
        "m = round(m, 5)\n",
        "b = round(b, 5)\n",
        "eq = 'y=' + str(m) + 'x+' + str(b)\n",
        "plt.text(100, 0.92, eq, fontsize=12)\n",
        "plt.title('DSC vs Ground Truth Volume')\n",
        "plt.xlabel('Ground Truth Volume: cm^3')\n",
        "plt.ylabel('DSC')\n",
        "#plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(volPred, DSC)\n",
        "m, b = np.polyfit(volPred, DSC, 1)\n",
        "plt.plot(volPred, m*volPred+b, color='red')\n",
        "m = round(m, 5)\n",
        "b = round(b, 5)\n",
        "eq = 'y=' + str(m) + 'x+' + str(b)\n",
        "plt.text(82, 0.92, eq, fontsize=12)\n",
        "plt.title('DSC vs Predicted Volume')\n",
        "plt.xlabel('Predicted Volume: cm^3')\n",
        "plt.ylabel('DSC')\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(volGT, volPred)\n",
        "m, b = np.polyfit(volGT, volPred, 1)\n",
        "plt.plot(volGT, m*volGT+b, color='red')\n",
        "m = round(m, 5)\n",
        "b = round(b, 5)\n",
        "eq = 'y=' + str(m) + 'x+' + str(b)\n",
        "plt.text(100, 80, eq, fontsize=12)\n",
        "plt.title('Predicted Volume vs Ground Truth Volume')\n",
        "plt.xlabel('Ground Truth Volume: cm^3')\n",
        "plt.ylabel('Predicted Volume: cm^3')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuBI_MXDts_4"
      },
      "source": [
        "testData = pd.read_excel('/content/gdrive/Shared drives/Andrew Mullen/Ventricle Segmentation/Data/TestImagesData.xlsx')\n",
        "print(testData['Volume Matlab'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCZ0rCqou7pY"
      },
      "source": [
        "# Volume Agrement\n",
        "\n",
        "vol1 = np.array(testData['Volume Matlab'])\n",
        "vol2 = np.array(volGT)\n",
        "matVolAgree = volAgree(vol1=vol1, vol2=vol2)\n",
        "vol1 = np.array(volPred)\n",
        "UnetVolAgree = volAgree(vol1=vol1, vol2=vol2)\n",
        "\n",
        "print(matVolAgree)\n",
        "print(UnetVolAgree)\n",
        "\n",
        "performance =[]\n",
        "y_pos = [0,1,3,4,6,7,9,10,12,13,15,16,18,19,21,22,24,25,27,28,30,31,33,34]\n",
        "objects = ('Unsupervised', 'Unet', 'Unsupervised', 'Unet', 'Unsupervised', 'Unet', 'Unsupervised', 'Unet', 'Unsupervised', 'Unet', 'Unsupervised', 'Unet', 'Unsupervised', 'Unet', 'Unsupervised', 'Unet', 'Unsupervised', 'Unet', 'Unsupervised', 'Unet', 'Unsupervised', 'Unet', 'Average Unsupervised', 'Average Unet')\n",
        "\n",
        "for i in range(len(matVolAgree)) :\n",
        "  performance.append(matVolAgree[i])\n",
        "  performance.append(UnetVolAgree[i])\n",
        "\n",
        "\n",
        "performance.append(sum(matVolAgree)/len(matVolAgree))\n",
        "performance.append(sum(UnetVolAgree)/len(UnetVolAgree))\n",
        "bar = plt.bar(y_pos, performance)\n",
        "\n",
        "bar[1].set_color('r')\n",
        "bar[3].set_color('r')\n",
        "bar[5].set_color('r')\n",
        "bar[7].set_color('r')\n",
        "bar[9].set_color('r')\n",
        "bar[11].set_color('r')\n",
        "bar[13].set_color('r')\n",
        "bar[15].set_color('r')\n",
        "bar[17].set_color('r')\n",
        "bar[19].set_color('r')\n",
        "bar[21].set_color('r')\n",
        "bar[23].set_color('r')\n",
        "plt.xticks(y_pos, objects, rotation='vertical')\n",
        "plt.title('Volume Agreement Between Segmentations and Ground Truths')\n",
        "plt.ylabel('Volume Agreement')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZV3d3BqHFYH"
      },
      "source": [
        "print(performance[-2])\n",
        "print(performance[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbT-_DVE5Qku"
      },
      "source": [
        "# Volume comparisons\n",
        "\n",
        "#objects = ('Matlab', 'Unet', 'GT', 'Matlab', 'Unet', 'GT', 'Matlab', 'Unet', 'GT', 'Matlab', 'Unet', 'GT', 'Matlab', 'Unet', 'GT', 'Matlab', 'Unet', 'GT', 'Matlab', 'Unet', 'GT', 'Matlab', 'Unet', 'GT', 'Matlab', 'Unet', 'GT', 'Matlab', 'Unet', 'GT', 'Matlab', 'Unet', 'GT', )\n",
        "#performance = []\n",
        "#y_pos = np.array(range(33))\n",
        "#tick=np.empty(33)\n",
        "for i in range(len(testData)) :\n",
        "  performance = [testData['Volume Matlab'][i], testData['Volume Unet'][i], testData['Volume GT'][i]]\n",
        "  y_pos = (3*i+i, 3*i+i+1, 3*i+i+2)\n",
        "  #tick.append(y_pos)\n",
        "\n",
        "  plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
        "\n",
        "  #plt.xticks(y_pos, objects, rotation='vertical')\n",
        "  plt.ylabel('cm^3')\n",
        "  plt.title('Volume')\n",
        "\n",
        "average = [sum(testData['Volume Matlab'])/11, sum(testData['Volume Unet'])/11, sum(testData['Volume GT'])/11]\n",
        "y_pos = ([44,45,46])\n",
        "plt.bar(y_pos, average, align='center', alpha=0.5)\n",
        "objects = ('Matlab', 'Unet', 'GT', 'Matlab', 'Unet', 'GT', 'Matlab', 'Unet', 'GT', 'Matlab', 'Unet', 'GT', 'Matlab', 'Unet', 'GT', 'Matlab', 'Unet', 'GT', 'Matlab', 'Unet', 'GT', 'Matlab', 'Unet', 'GT', 'Matlab', 'Unet', 'GT', 'Matlab', 'Unet', 'GT', 'Matlab', 'Unet', 'GT', 'Average Matlab', 'Average Unet', 'Average GT')\n",
        "#performance = []\n",
        "y_pos = np.array([0,1,2,4,5,6,8,9,10,12,13,14,16,17,18,20,21,22,24,25,26,28,29,30,32,33,34,36,37,38,40,41,42,44,45,46])\n",
        "\n",
        "plt.xticks(y_pos, objects, rotation='vertical')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIIhLiEsDNiU"
      },
      "source": [
        "len(performance)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uv8ahuYT_kbn"
      },
      "source": [
        "# Troubleshooting\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8bkw89AaYry"
      },
      "source": [
        "VOL_path = 'Data/Standardized/v2/'\n",
        "GT_path = 'Data/Ground Truths/'\n",
        "BRAIN_path = 'Data/Masks/Brain/U-Net/'\n",
        "\n",
        "vol_dir = os.listdir(VOL_path)\n",
        "loadmat(VOL_path + vol_dir[2])['im']['hdr']#['PixelSpacing']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUw5t8j59eis"
      },
      "source": [
        "len(DSC_unsup[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4blqzbRbmT5"
      },
      "source": [
        "image = VOL[44][:,:,28]\n",
        "label = GT[44][:,:,28]\n",
        "\n",
        "imsave('/content/gdrive/Shared drives/Andrew Mullen/Ventricle Segmentation/image.png', image, cmap='gray', origin='upper')\n",
        "imsave('/content/gdrive/Shared drives/Andrew Mullen/Ventricle Segmentation/label.png', label, cmap='gray', origin='upper')\n",
        "\n",
        "image = imread('/content/gdrive/Shared drives/Andrew Mullen/Ventricle Segmentation/image.png')\n",
        "label = imread('/content/gdrive/Shared drives/Andrew Mullen/Ventricle Segmentation/label.png')\n",
        "\n",
        "f, axarr = plt.subplots(1, 2)\n",
        "axarr[0].imshow(image, cmap=\"gray\")\n",
        "axarr[1].imshow(label, cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PftVzliqH-Jn"
      },
      "source": [
        "import random as rd\n",
        "x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
        "rd.shuffle(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hf09CAHrIMds"
      },
      "source": [
        "print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wYBEFrQIQ85"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}